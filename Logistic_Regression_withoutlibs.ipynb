{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gL8XY7dN24PJ"
   },
   "outputs": [],
   "source": [
    "# Created by GB - 10/22\n",
    "# Google Colab was used in this code\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import PIL\n",
    "import pathlib\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XyvzsRJh29on",
    "outputId": "66c3e6a7-5c46-48a7-fc90-1c80731189d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive/\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')\n",
    "path1 = r'/content/drive/MyDrive/Colab Notebooks/Images/iron man comics_dir_resized'\n",
    "path2 = r'/content/drive/MyDrive/Colab Notebooks/Images/spider man comics_dir_resized'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rmFt7y4s292m"
   },
   "outputs": [],
   "source": [
    "    ## Preparing the data ##\n",
    "\n",
    "# Convert images into numpy arrays #\n",
    "# Concatenate the arrays #\n",
    "# Shuffle #\n",
    "# Split into train and test sets #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VovHMIc_29rg"
   },
   "outputs": [],
   "source": [
    "# Converting images to numpy arrays \n",
    "def numpy_arrays(path1,path2):\n",
    "    delimiter = chr(92)\n",
    "    path_list = []\n",
    "    arrays_list1 = []\n",
    "    arrays_list2 = []\n",
    "    path_list.append(path1)\n",
    "    path_list.append(path2)\n",
    "    counter = 0\n",
    "    for paths in range(len(path_list)):\n",
    "        listdir = os.listdir(path_list[paths])\n",
    "        counter += 1\n",
    "        for items in listdir:\n",
    "            items.split()\n",
    "            if counter == 1:\n",
    "                image = PIL.Image.open(path1+'/'+items) #problem with delimiter !WARNING!\n",
    "            else:\n",
    "                image = PIL.Image.open(path2+'/'+items)\n",
    "            image_inf = image.getdata()\n",
    "            sub_array = np.array(image_inf)\n",
    "            if counter == 1:\n",
    "                arrays_list1.append(sub_array)\n",
    "            else:\n",
    "                arrays_list2.append(sub_array)\n",
    "    \n",
    "    ones= np.ones((len(arrays_list1),), dtype=int)\n",
    "    ones = ones.tolist()\n",
    "    zeros= np.zeros((len(arrays_list2),), dtype=int)\n",
    "    zeros = zeros.tolist()\n",
    "    return arrays_list1,arrays_list2,ones,zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8lfLI2RJ29t2"
   },
   "outputs": [],
   "source": [
    "def conc_lists(array1,array2,ones,zeros):\n",
    "    arrayX = array1\n",
    "    arrayY = ones\n",
    "    for i in range(len(array2)):\n",
    "        arrayX.append(array2[i])\n",
    "    for x in range(len(zeros)):\n",
    "        arrayY.append(zeros[x])\n",
    "        \n",
    "    return arrayX, arrayY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2RSRYxdm29xJ"
   },
   "outputs": [],
   "source": [
    "def shuffle(X1,X2):\n",
    "    X3 = list(zip(X1,X2))\n",
    "    random.shuffle(X3)\n",
    "    X1,X2 = zip(*X3)\n",
    "    return X1,X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2rZAY7dS29z0"
   },
   "outputs": [],
   "source": [
    "def train_test_split(array1,array2,train_size):\n",
    "    len_array1 = len(array1)\n",
    "    len_array2 = len(array2)\n",
    "    array1_train_size = int(train_size*len_array1)\n",
    "    array2_train_size = int(train_size*len_array2)\n",
    "    X_train = array1[:array1_train_size]\n",
    "    Y_train = array2[:array1_train_size]\n",
    "    X_test = array1[array2_train_size:]\n",
    "    Y_test = array2[array2_train_size:]\n",
    "    return X_train,Y_train,X_test,Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5R07FV4g295p",
    "outputId": "513aae91-d2e4-4167-9fb9-f69b0329c83d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class 1 len:  656\n",
      "class 1 data type:  <class 'list'>\n",
      "class 1 image size (multiplicated):  (160000,)\n",
      "class 2 len:  656\n",
      "class 2 data type:  <class 'list'>\n",
      "class 2 image size (multiplicated):  (160000,)\n",
      "class 1 y len:  656\n"
     ]
    }
   ],
   "source": [
    "array1,array2,ones,zeros=numpy_arrays(path1,path2)\n",
    "print('class 1 len: ',len(array1))\n",
    "print('class 1 data type: ',type(array1))\n",
    "print('class 1 image size (multiplicated): ',array1[1].shape)\n",
    "print('class 2 len: ',len(array2))\n",
    "print('class 2 data type: ',type(array2))\n",
    "print('class 2 image size (multiplicated): ',array2[1].shape)\n",
    "print('class 1 y len: ',len(ones))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NtkdjjQ83HwH",
    "outputId": "d0c40699-e5f3-475c-81bf-4ceee85a3813"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1312"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This part is used to concancate class arrays and their y values\n",
    "arrayX,arrayY = conc_lists(array1,array2,ones,zeros)\n",
    "len(arrayY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gD9X0M9a3Hyd",
    "outputId": "03f2df30-9e86-4a5a-f7d3-7b8db7777e43"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1312"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This part is used to shuffle all data with same way.\n",
    "# After running, we have more realistic data to classificate\n",
    "array_X,array_Y = shuffle(arrayX,arrayY)\n",
    "len(array_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YNk0u7b1298F",
    "outputId": "5668cce9-2d3a-4846-d1b3-bde03eb74dc7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of X values of train data:  1180\n",
      "length of Y values of train data:  1180\n",
      "length of X values of test data:  132\n",
      "length of Y values of test data:  132\n"
     ]
    }
   ],
   "source": [
    "# This part is to split the data into train and test datas.\n",
    "train_X,train_Y,test_X,test_Y=train_test_split(array_X,array_Y,train_size=0.9)\n",
    "print('length of X values of train data: ',len(train_X))\n",
    "print('length of Y values of train data: ',len(train_Y))\n",
    "print('length of X values of test data: ',len(test_X))\n",
    "print('length of Y values of test data: ',len(test_Y))\n",
    "train_X = np.array(train_X)\n",
    "train_Y = np.array(train_Y)\n",
    "test_X = np.array(test_X)\n",
    "test_Y = np.array(test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0sX5O2MG_OEU"
   },
   "outputs": [],
   "source": [
    "# Normalizing the datas #\n",
    "standard_X_train =  (train_X - np.average(train_X)) / (np.std(train_X))\n",
    "standard_X_test =  (test_X - np.average(test_X)) / (np.std(test_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c52JGJS64OrI"
   },
   "outputs": [],
   "source": [
    "### Classification with Logistic Regression ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I8-vmxlO609G"
   },
   "outputs": [],
   "source": [
    "# Sigmoid function for logistic regression #\n",
    "def sigmoid_function(x):\n",
    "    return 1 / (1 + np.exp(-1*x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "txnJWD6T-R05"
   },
   "outputs": [],
   "source": [
    "def loss_gradient(x,y,sig_y):\n",
    "    return np.dot(x.T,(sig_y-y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0DA9WMRy9HBw"
   },
   "outputs": [],
   "source": [
    "# Defining cross entropy loss #\n",
    "def cross_entropy(y,t):\n",
    "    return -1 * (t * np.log(y) + (1 - t) * np.log(1 - y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ONCvV22HBgLC"
   },
   "outputs": [],
   "source": [
    "def accuracy_s(y_true,y_pred):\n",
    "    len_of_t = len(y_true)\n",
    "    len_of_p = len(y_pred)\n",
    "    true = 0\n",
    "    if len_of_t != len_of_p:\n",
    "        print(\"The sizes are not matched !\")\n",
    "    else:\n",
    "        for _ in range(len_of_t):\n",
    "            if y_true[_]==y_pred[_]:\n",
    "                true += 1\n",
    "    \n",
    "    accuracy = true/len_of_t\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XhEsioNw_B4x"
   },
   "outputs": [],
   "source": [
    "# Parameter initialization #\n",
    "param_init = {}\n",
    "param_init[\"w\"] = np.random.randn(train_X.shape[1])\n",
    "param_init[\"b\"] = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J2sEFxzP5aPq",
    "outputId": "5d83fa4e-78d6-4233-a7ae-f504dfc21afb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160000,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_init[\"w\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qRCvwtRo7iwd"
   },
   "outputs": [],
   "source": [
    "# Logistic regression parameter optimization #\n",
    "def logreg(x,y,parameters,n_iterations,lrate):\n",
    "    lenx = len(x)\n",
    "    w = parameters[\"w\"]\n",
    "    b = parameters[\"b\"]\n",
    "    loss_list = []\n",
    "\n",
    "    for _ in range(n_iterations):\n",
    "        sig_y = sigmoid_function(np.dot(x,w)+b)\n",
    "        cross_loss = cross_entropy(sig_y,y)\n",
    "        loss_list.append(cross_loss)\n",
    "        dW = loss_gradient(x,y,sig_y) / lenx\n",
    "        db = np.sum(sig_y-y) / lenx\n",
    "        new_w = w - lrate * dW\n",
    "        new_b = b - lrate * db\n",
    "    \n",
    "    parameters[\"w\"] = new_w\n",
    "    parameters[\"b\"] = new_b\n",
    "    return parameters,loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PaJ6UgXD_AUk"
   },
   "outputs": [],
   "source": [
    "# Defining parameters and training the model #\n",
    "warnings.filterwarnings('ignore')\n",
    "lrate = 0.001\n",
    "n_iterations = 1000\n",
    "parameters_obtained,loss = logreg(standard_X_train,train_Y,param_init,n_iterations,lrate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QszKC67J_AWw"
   },
   "outputs": [],
   "source": [
    "# Accuracy with test data\n",
    "new_test_X = np.dot(standard_X_test, parameters_obtained[\"w\"] ) + parameters_obtained[\"b\"] \n",
    "new_test_y = sigmoid_function(new_test_X) > 1/2  \n",
    "new_test_y = [int(y) for y in new_test_y]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sHtfgulh_AYW",
    "outputId": "a6567c66-0c65-46b1-99c1-d0962ff42d63"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5227272727272727"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_s(test_Y,new_test_y)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "77e2eTBVwPjj",
    "outputId": "2091997f-3e4a-4a94-97de-610b3a7f5adb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5303030303030303"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sklearn Example\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "logregsk = LogisticRegression(max_iter=3000)\n",
    "logregsk.fit(standard_X_train,train_Y)\n",
    "pred_logreg = logregsk.predict(standard_X_test)\n",
    "accuracy_sk = accuracy_score(test_Y, pred_logreg)\n",
    "accuracy_sk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qCnls_tVVPvw",
    "outputId": "9b1956fa-0e22-4366-f3d6-9471b749ba70"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'w': array([-0.05846678,  2.46380384,  0.56637152, ...,  0.86249728,\n",
       "         0.09738942,  0.62857064]), 'b': 0.049937821917104046}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters_obtained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L27YFAktYd-Q"
   },
   "outputs": [],
   "source": [
    "# Tuning\n",
    "n_iterations_list = [300, 400, 500, 600, 700]\n",
    "lrate_list = [0.001, 0.01, 0.1, 0.5, 1]\n",
    "accuracy_list = []\n",
    "Tuning_list = []\n",
    "loss_list = []\n",
    "for k in n_iterations_list:\n",
    "    for i in lrate_list:\n",
    "        parameters_obtained,loss = logreg(standard_X_train,train_Y,param_init,k,i)\n",
    "        new_test_X = np.dot(standard_X_test, parameters_obtained[\"w\"] ) + parameters_obtained[\"b\"] \n",
    "        new_test_y = sigmoid_function(new_test_X) > 1/2  \n",
    "        new_test_y = [int(y) for y in new_test_y]\n",
    "        accuracy = accuracy_s(test_Y,new_test_y)\n",
    "        accuracy_list.append(accuracy)\n",
    "        arb_list = [k,i,accuracy]\n",
    "        Tuning_list.append(arb_list)\n",
    "        loss_list.append(loss)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
